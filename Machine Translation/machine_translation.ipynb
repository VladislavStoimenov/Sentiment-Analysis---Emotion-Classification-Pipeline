{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Training Machine Translation Model and Translating the Whisper file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import transformers\n",
    "import tensorflow as tf\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "from transformers import AdamWeightDecay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pre-trained model - [opus-mt-bg-en](https://huggingface.co/Helsinki-NLP/opus-mt-bg-en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chechpoint =\"Helsinki-NLP/opus-mt-bg-en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset - [opus100/bg-en](https://huggingface.co/datasets/Helsinki-NLP/opus-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125f5c76e2ac40ccafb9d7f104bbc544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/65.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0dc02f3d214beba039400ec95eb1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/160k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d93c3bf1164974a2984ba44452959a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/71.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec85ae6706b427dba366d1a1b420c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/154k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f960c5c3b64c35a2e2823d7fa61c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffa6d46245042f7825ae95b1f150ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7256da1ef114bb396924b3c8cb38810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"opus100\", \"bg-en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1000000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check an example of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'bg': 'Сериозно ли?', 'en': 'Are you serious?'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWJsj3Tp5rKU"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "# load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_chechpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[671, 3, 339, 35, 880, 5, 0], [578, 1131, 22, 6784, 22, 1930, 12, 2250, 5, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize sentences to check the tokenizer\n",
    "tokenizer(['Здравей, как си днес?', 'How are you today?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define PreProcessing function to tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define max length of input and target\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "# define the source and target language\n",
    "source_lang = 'bg'\n",
    "target_lang = 'en'\n",
    "# define preprocess function to tokenize the input and target\n",
    "def preprocess_function(examples):\n",
    "  # Tokenize the inputs and targets\n",
    "  inputs = [ex[source_lang] for ex in examples[\"translation\"]]\n",
    "  targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "  # Setup the tokenizer for targets\n",
    "  model_inputs = tokenizer(inputs, max_length=max_target_length, truncation=True)\n",
    "\n",
    "  # Setup the tokenizer for targets\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "  # return the model inputs\n",
    "  return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the function to a sample from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[4258, 49, 5, 0], [644, 103, 28, 0]], 'attention_mask': [[1, 1, 1, 1], [1, 1, 1, 1]], 'labels': [[468, 14, 1681, 5, 0], [22, 662, 28, 0]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(dataset[\"train\"][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the preprocess function to the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f206edd6d0455386e00005755795c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4a13aff0a24e8aaf9b1efb397dffff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aeb57e09bb2447d9cd10944555c0022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the dataset\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120ebcde39b54c96b09ac0e788723727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/306M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 13:37:05.952852: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-03-22 13:37:05.954336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46228 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-bg-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Define model configuration\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_chechpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameter for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "num_train_epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data collator\n",
    "generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\", pad_to_multiple_of=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training set\n",
    "train_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_datasets[\"train\"], # Use thre train set from the tokenized dataset\n",
    "    batch_size=batch_size, # define the batch size\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator, # collate function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define validation set\n",
    "validation_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_datasets[\"validation\"], # Use thre validation set from the tokenized dataset\n",
    "    batch_size=batch_size, # define the batch size\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator, # collate function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator dataset\n",
    "generation_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_datasets[\"validation\"], # Use thre validation set from the tokenized dataset \n",
    "    batch_size=8, # Set the batch size to 8\n",
    "    shuffle=False,\n",
    "    collate_fn=generation_data_collator, # use the generation data collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer - AdamWeightDecay\n",
    "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\n",
    "# compile the model with the optimizer\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "62500/62500 [==============================] - 4092s 65ms/step - loss: 1.5482 - val_loss: 1.5626\n",
      "Epoch 2/3\n",
      "62500/62500 [==============================] - 4051s 65ms/step - loss: 1.4994 - val_loss: 1.5759\n",
      "Epoch 3/3\n",
      "62500/62500 [==============================] - 4035s 65ms/step - loss: 1.4633 - val_loss: 1.6020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7fdc84111350>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using the train and validation sets for the defined number of epochs\n",
    "model.fit(train_dataset, validation_data=validation_dataset, epochs=num_train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:397: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61812]]}\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# save the model in folder tf_model\n",
    "model.save_pretrained(\"tf_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Test the model on translating a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at tf_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_chechpoint)\n",
    "# load the model from tf_model\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"tf_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 13), dtype=int32, numpy=\n",
       "array([[61812,    11,   111,    12,  1366,  4669,   220,    33,  5266,\n",
       "           10,  1629,     2,     0]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define input text to test the model\n",
    "input_text = 'Обичам да чета книги, когато навън вали дъжд.'\n",
    "# tokenize the input text\n",
    "tokenized = tokenizer([input_text], return_tensors='np')\n",
    "# generate the output\n",
    "out = model.generate(**tokenized, max_length=128)\n",
    "# print the tokens\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like to read books when it rains outside.\n"
     ]
    }
   ],
   "source": [
    "# decode the output tokens to get the translation\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    # decode the output tokens\n",
    "    print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "## Use the model to translate the transcript from Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas to read the csv file\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and tokenizer from the saved model\n",
    "model_chechpoint =\"Helsinki-NLP/opus-mt-bg-en\"\n",
    "# load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_chechpoint)\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"tf_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Whisper CSV file and use the first 200 lines (4 group members/50 for each for quality check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the file path to Whisper CSV file\n",
    "file_path = \"STT_Whisper.csv\"\n",
    "# read the csv file\n",
    "df = pd.read_csv(file_path).head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the first 10 lines before translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>СОФИЯ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>34,68</td>\n",
       "      <td>Той беше обещал, че ще я сълбажда, че ще я тъ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35,46</td>\n",
       "      <td>38,1</td>\n",
       "      <td>Тя много страдаше, много плачеше.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>42,92</td>\n",
       "      <td>Аз по някакъв начин исках да компенсирам него...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43,52</td>\n",
       "      <td>47,3</td>\n",
       "      <td>затова си позволих да ѝ купувам всичко, какво...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47,96</td>\n",
       "      <td>50,12</td>\n",
       "      <td>обаче с годините ми се качи на главата.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51,12</td>\n",
       "      <td>54,04</td>\n",
       "      <td>Отношенията между майка и дъщеря се влушават ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54,4</td>\n",
       "      <td>56,38</td>\n",
       "      <td>когато новият приятел на Лилияна, Теодор,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>56,38</td>\n",
       "      <td>59,96</td>\n",
       "      <td>се нанася да живее при тях заедно с сина си Н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>65,16</td>\n",
       "      <td>Дори и най-дредната молба за помощ от страна ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Start Time End Time                                      Transcription\n",
       "0          0        2                                              СОФИЯ\n",
       "1         30    34,68   Той беше обещал, че ще я сълбажда, че ще я тъ...\n",
       "2      35,46     38,1                  Тя много страдаше, много плачеше.\n",
       "3         39    42,92   Аз по някакъв начин исках да компенсирам него...\n",
       "4      43,52     47,3   затова си позволих да ѝ купувам всичко, какво...\n",
       "5      47,96    50,12            обаче с годините ми се качи на главата.\n",
       "6      51,12    54,04   Отношенията между майка и дъщеря се влушават ...\n",
       "7       54,4    56,38          когато новият приятел на Лилияна, Теодор,\n",
       "8      56,38    59,96   се нанася да живее при тях заедно с сина си Н...\n",
       "9         60    65,16   Дори и най-дредната молба за помощ от страна ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to iterate over each of the sentences and get their translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the translations\n",
    "translations = []\n",
    "# for loop to iterate over the sentences in the Transcription column\n",
    "for sentence in df[\"Transcription\"]:\n",
    "    # tokenize the sentence\n",
    "    tokenized = tokenizer([sentence], return_tensors='np', max_length=128, truncation=True)\n",
    "    # generate the output\n",
    "    output = model.generate(**tokenized, max_length=128)\n",
    "    # decode the output tokens\n",
    "    translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    # append the translation to the list\n",
    "    translations.append(translation)\n",
    "# add the translations to the dataframe as a new column\n",
    "df[\"Translation\"] = translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the first 10 lines after translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>Translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>СОФИЯ</td>\n",
       "      <td>SOFIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>34,68</td>\n",
       "      <td>Той беше обещал, че ще я сълбажда, че ще я тъ...</td>\n",
       "      <td>He promised he'd say he'd look for her, but he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35,46</td>\n",
       "      <td>38,1</td>\n",
       "      <td>Тя много страдаше, много плачеше.</td>\n",
       "      <td>She was in a lot of pain, a lot of crying.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>42,92</td>\n",
       "      <td>Аз по някакъв начин исках да компенсирам него...</td>\n",
       "      <td>I somehow wanted to compensate for his absence,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43,52</td>\n",
       "      <td>47,3</td>\n",
       "      <td>затова си позволих да ѝ купувам всичко, какво...</td>\n",
       "      <td>So I took the liberty of buying her everything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47,96</td>\n",
       "      <td>50,12</td>\n",
       "      <td>обаче с годините ми се качи на главата.</td>\n",
       "      <td>But over the years, he got on my head.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51,12</td>\n",
       "      <td>54,04</td>\n",
       "      <td>Отношенията между майка и дъщеря се влушават ...</td>\n",
       "      <td>The relationship between a mother and a daught...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54,4</td>\n",
       "      <td>56,38</td>\n",
       "      <td>когато новият приятел на Лилияна, Теодор,</td>\n",
       "      <td>When Liliana's new friend, Theodore,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>56,38</td>\n",
       "      <td>59,96</td>\n",
       "      <td>се нанася да живее при тях заедно с сина си Н...</td>\n",
       "      <td>moved in with his son, Nicholas, to live with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>65,16</td>\n",
       "      <td>Дори и най-дредната молба за помощ от страна ...</td>\n",
       "      <td>Even the most appropriate request for help fro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Start Time End Time                                      Transcription  \\\n",
       "0          0        2                                              СОФИЯ   \n",
       "1         30    34,68   Той беше обещал, че ще я сълбажда, че ще я тъ...   \n",
       "2      35,46     38,1                  Тя много страдаше, много плачеше.   \n",
       "3         39    42,92   Аз по някакъв начин исках да компенсирам него...   \n",
       "4      43,52     47,3   затова си позволих да ѝ купувам всичко, какво...   \n",
       "5      47,96    50,12            обаче с годините ми се качи на главата.   \n",
       "6      51,12    54,04   Отношенията между майка и дъщеря се влушават ...   \n",
       "7       54,4    56,38          когато новият приятел на Лилияна, Теодор,   \n",
       "8      56,38    59,96   се нанася да живее при тях заедно с сина си Н...   \n",
       "9         60    65,16   Дори и най-дредната молба за помощ от страна ...   \n",
       "\n",
       "                                         Translation  \n",
       "0                                              SOFIA  \n",
       "1  He promised he'd say he'd look for her, but he...  \n",
       "2         She was in a lot of pain, a lot of crying.  \n",
       "3    I somehow wanted to compensate for his absence,  \n",
       "4  So I took the liberty of buying her everything...  \n",
       "5             But over the years, he got on my head.  \n",
       "6  The relationship between a mother and a daught...  \n",
       "7               When Liliana's new friend, Theodore,  \n",
       "8  moved in with his son, Nicholas, to live with ...  \n",
       "9  Even the most appropriate request for help fro...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the dataframe az Excell file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation done!\n"
     ]
    }
   ],
   "source": [
    "df.to_excel(\"translations_score.xlsx\", index=False)\n",
    "print(\"Translation done!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
